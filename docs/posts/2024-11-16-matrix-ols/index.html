<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.3">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Josue Rodriguez">
<meta name="dcterms.date" content="2024-11-16">
<meta name="description" content="I go over OLS regression in matrix notation, and show how it connects to the scalar notation of OLS regression.">

<title>Connecting Scalar and Matrix Notation in OLS Regression – josue rodriguez</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2b7e86a45101691e9cf9029500fe0614.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-b9080fd8af111c1303e26c7e65ee2a26.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">josue rodriguez</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">about</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">posts</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Connecting Scalar and Matrix Notation in OLS Regression</h1>
                  <div>
        <div class="description">
          <p>I go over OLS regression in matrix notation, and show how it connects to the scalar notation of OLS regression.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">statistics</div>
                <div class="quarto-category">regression</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Josue Rodriguez </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 16, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ols-in-scalar-notation" id="toc-ols-in-scalar-notation" class="nav-link active" data-scroll-target="#ols-in-scalar-notation">OLS in scalar notation</a></li>
  <li><a href="#ols-in-matrix-notation" id="toc-ols-in-matrix-notation" class="nav-link" data-scroll-target="#ols-in-matrix-notation">OLS in matrix notation</a></li>
  <li><a href="#deriving-the-ols-estimator-using-matrix-notation" id="toc-deriving-the-ols-estimator-using-matrix-notation" class="nav-link" data-scroll-target="#deriving-the-ols-estimator-using-matrix-notation">Deriving the OLS estimator using matrix notation</a>
  <ul class="collapse">
  <li><a href="#elements-of-hatboldsymbolbeta" id="toc-elements-of-hatboldsymbolbeta" class="nav-link" data-scroll-target="#elements-of-hatboldsymbolbeta">Elements of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></a></li>
  </ul></li>
  <li><a href="#deriving-the-sampling-distribution-of-hatboldsymbolbeta" id="toc-deriving-the-sampling-distribution-of-hatboldsymbolbeta" class="nav-link" data-scroll-target="#deriving-the-sampling-distribution-of-hatboldsymbolbeta">Deriving the sampling distribution of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></a>
  <ul class="collapse">
  <li><a href="#elements-of-the-variance-covariance-matrix" id="toc-elements-of-the-variance-covariance-matrix" class="nav-link" data-scroll-target="#elements-of-the-variance-covariance-matrix">Elements of the variance-covariance matrix</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">
\(
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\)





<p>I think my journey in statistics has been unconventional in that much of my statistical training came from social-behavioral stats classes, where the heavier math is often left at the door, and so I missed out on a lot of the intuition and proofs that many statistics students see in their undergraduate courses.</p>
<p>For me, this is certainly the case in connecting the estimating equations for the regression parameters (and their variances) that you learn in intro statistics courses to the estimating equation in the matrix form of OLS. I know the scalar equations and I know the matrix equation. But I haven’t seen how it is that they result in the same estimates.</p>
<p>This gap in understanding led me to reflect on a statistics professor I had during my master’s program. When it came to derivations with important results, he’d often insist that we “see it once!”. I think what he wanted was for us to know that the methods he was teaching stood on solid ground, and not necessarily for us to memorize each step of the derivation. The idea of “see it once” always struck me as a valuable principle.</p>
<p>This post is another opportunity to “see it once”, bridging the scalar and matrix notations of OLS. The derivations below follow Chapter 11 of Cosma Shalizi’s <em>The Truth about Linear Regression</em>, with a few added details for clarity.</p>
<section id="ols-in-scalar-notation" class="level1">
<h1>OLS in scalar notation</h1>
<p>OLS regression is typically presented in its simplest (and, I think clearest) form in introductory statistics classes</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \epsilon_i,\quad i = 1, \dots, n.
\]</span></p>
<p>The goal is to predict <span class="math inline">\(y_i\)</span> from <span class="math inline">\(x_i\)</span>, with the optimal linear prediction of <span class="math inline">\(y_i\)</span> given <span class="math inline">\(x_i\)</span> obtained when the regression parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> minimize the sum of the squared residuals (RSS). The parameters that accomplish this are given by the following equations</p>
<p><span class="math display">\[
\begin{align}
\hat \beta_1 &amp;= \frac{\hat{\text{Cov}(x, y)}}{\hat \sigma^2_x}  \\
\hat \beta_0 &amp;= \bar y -  \hat \beta_1 \bar x.
\end{align}
\]</span></p>
<p>Assuming homoskedastic and independent errors, the variances of the regression parameters can be calculated as follows</p>
<p><span class="math display">\[
\mathbb{V}(\beta_0) = \frac{\sigma^2_\epsilon}{n} \left( 1 + \frac{\bar x^2}{\sigma^2_x} \right)
\]</span></p>
<p><span class="math display">\[
\mathbb{V}(\beta_1) = \frac{\sigma^2_{\epsilon}}{\sum_{i=1}^n (x_i - \bar x)^2}.
\]</span></p>
</section>
<section id="ols-in-matrix-notation" class="level1">
<h1>OLS in matrix notation</h1>
<p>While the equations in scalar notation are intuitive for simple regression, they become unwieldy with multiple predictors. This is where matrix notation comes in handy since it gives us a nice, compact notation. However, we’ll stick to the case of a single predictor so that we can focus on connecting the scalar notation to the matrix notation.</p>
<p>The equation connecting <span class="math inline">\(y_i\)</span> to <span class="math inline">\(x_i\)</span> can be re-written using vectors and matrices</p>
<p><span class="math display">\[
\begin{align}
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix} &amp;=
\begin{bmatrix}
\beta_0 + \beta_1 x_i + \epsilon_1\\
\vdots \\
\beta_0 + \beta_1 x_n + \epsilon_n
\end{bmatrix} \\
%------------------
&amp;=
\begin{bmatrix}
1 &amp; x_1 \\
\vdots &amp; \vdots \\
1 &amp; x_n
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1 \\
\vdots \\
\epsilon_i \\
\end{bmatrix}.
\end{align}
\]</span></p>
<p>We can compactly write</p>
<p><span class="math display">\[
\begin{align}
\mathbf{y} = \mathbf{x} \bm{\beta} + \bm{\epsilon}.
\end{align}
\]</span></p>
<p>The regression parameters that minimize the RSS are given by <span class="math display">\[
\hat{\bm{\beta}} = \begin{bmatrix} \hat\beta_0 \\ \hat\beta_1\end{bmatrix} = \left(\mathbf{x}'\mathbf{x}\right)^{-1} \mathbf{x}'\mathbf{y}
\]</span></p>
<p>and the variance-covariance matrix of the estimated coefficients by</p>
<p><span class="math display">\[
\bm{\Sigma} = \begin{bmatrix} \mathbb{V}[\hat\beta_0] &amp; \text{Cov}(\hat\beta_0, \hat\beta_1) \\ \text{Cov}(\hat\beta_1, \hat\beta_0) &amp;  \mathbb{V}[\hat\beta_1]\end{bmatrix} = \sigma^2_\epsilon (\bm{x}'\bm{x})^{-1}.
\]</span></p>
</section>
<section id="deriving-the-ols-estimator-using-matrix-notation" class="level1">
<h1>Deriving the OLS estimator using matrix notation</h1>
<p>The first step we’ll take in connecting the scalar notation equations to the matrix equation is to show that the matrix estimator yields a parameter vector that minimizes the RSS.</p>
<p>The residuals can be collected in a vector that can subsequently be used to compute the residual sum of squares (RSS)</p>
<p><span class="math display">\[
\begin{align}
\bm \epsilon &amp;= \begin{bmatrix}
y_1 - \hat y_1 \\
\vdots \\
y_n - \hat y_n
\end{bmatrix} \\
&amp;= \mathbf{y} - \hat{\mathbf{y}} \\
&amp;= \mathbf{y} - \mathbf{x} \bm{\beta}.
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
\text{RSS} &amp;= \epsilon'\epsilon \\
&amp;= \left(\mathbf{y} - \mathbf{x} \bm{\beta} \right)' \left(\mathbf{y} - \mathbf{x} \bm{\beta} \right).
\end{align}
\]</span></p>
<p>Expanding the terms in the RSS results in the following expression</p>
<p><span class="math display">\[
=
  \mathbf{y}'\mathbf{y} -
  2\bm{\beta}'\mathbf{x}'\mathbf{y} +
  \bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta}.
\]</span></p>
<p>If you’re curious, the intervening steps can be found by expanding the box below.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="RSS Details">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
RSS Details
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The tranpose of matrix product satisfies <span class="math inline">\((AB)' = B'A'\)</span>. Using this property, we get</p>
<p><span class="math display">\[
\text{RSS} = \left(\mathbf{y}' -\bm{\beta}'\mathbf{x}'\right) \left(\mathbf{y} - \mathbf{x} \bm{\beta} \right).
\]</span></p>
<p>Expanding the equation we get</p>
<p><span class="math display">\[
= \mathbf{y}'\mathbf{y} -
\mathbf{y}'\mathbf{x}\bm{\beta} -
\bm{\beta}'\mathbf{x}'\mathbf{y} +
\bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta}
\]</span></p>
<p>Now, notice this little bit here <span class="math inline">\(\bm{\beta}'\mathbf{x}'\mathbf{y}\)</span>. If we again apply the above tranpose of a product rule we get <span class="math inline">\(\bm{\beta}'\mathbf{x}'\mathbf{y} = \left(\mathbf{y}'\mathbf{x}\bm{\beta} \right)'\)</span>.</p>
<ul>
<li>Also, this results in a <span class="math inline">\(1 \times 1\)</span> matrix, so <span class="math inline">\(\left(\mathbf{y}'\mathbf{x}\bm{\beta} \right)' = \mathbf{y}'\mathbf{x}\bm{\beta}\)</span>.</li>
</ul>
<p>Substituting <span class="math inline">\(\mathbf{y}'\mathbf{x}\bm{\beta}\)</span> in the RSS equation with <span class="math inline">\(\bm{\beta}'\mathbf{x}'\mathbf{y}\)</span> we get</p>
<p><span class="math display">\[
\begin{align}
&amp;= \mathbf{y}'\mathbf{y} -
\bm{\beta}'\mathbf{x}'\mathbf{y} -
\bm{\beta}'\mathbf{x}'\mathbf{y} ++
\bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta} \\
&amp;=
  \mathbf{y}'\mathbf{y} -
  2\bm{\beta}'\mathbf{x}'\mathbf{y} +
  \bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta}
\end{align}
\]</span></p>
</div>
</div>
</div>
<hr>
<p>To determine the vector <span class="math inline">\(\bm{\beta}\)</span> that minimizes the residual sum of squares (RSS), we differentiate the RSS with respect to <span class="math inline">\(\bm{\beta}\)</span>, set the resulting expression equal to zero, and solve for <span class="math inline">\(\bm{\beta}\)</span>.</p>
<p>The gradient turns out to be given by</p>
<p><span class="math display">\[
\begin{align}
\nabla \text{RSS} &amp;=
  \nabla \mathbf{y}'\mathbf{y} -
  2 \nabla \bm{\beta}'\mathbf{x}'\mathbf{y} +
  \nabla \bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta}
\\
&amp;= 2 \left( \mathbf{x}'\mathbf{x}\bm{\beta} - \mathbf{x}'\mathbf{y} \right).
\end{align}
\]</span></p>
<p>Again, the curious can find details by expanding the box below.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Gradient Details">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Gradient Details
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Differentiating term by term:</p>
<p><span class="math display">\[
\nabla \mathbf{y}'\mathbf{y} = 0
\]</span></p>
<ul>
<li>Because <span class="math inline">\(\mathbf{y}'\mathbf{y}\)</span> is fixed.</li>
</ul>
<p><span class="math display">\[
-2 \nabla \bm{\beta}'\mathbf{x}'\mathbf{y} = -2 \mathbf{x}' \mathbf{y}
\]</span></p>
<ul>
<li>Because <span class="math inline">\(\frac{\partial \mathbf{x}'\mathbf{a}}{\partial \mathbf{x}} = \mathbf{a}\)</span></li>
</ul>
<p><span class="math display">\[
\nabla \bm{\beta}'\mathbf{x}'\mathbf{x}\bm{\beta} = 2 \mathbf{x}'\mathbf{x}\bm{\beta}
\]</span></p>
<ul>
<li>Because <span class="math inline">\(\mathbf{x}'\mathbf{x}\)</span> is symmetric, and if <span class="math inline">\(\mathbf{A}\)</span> is symmetric, <span class="math inline">\(\frac{\partial \mathbf{x}'\mathbf{A}\mathbf{x}}{\partial \mathbf{x}} = 2\mathbf{A}\mathbf{x}\)</span></li>
</ul>
<p>Gluing it back together we get</p>
<p><span class="math display">\[
\begin{align}
\nabla \text{RSS} &amp;=
  -2 \mathbf{x}' \mathbf{y} + 2 \mathbf{x}'\mathbf{x}\bm{\beta}
  \\
&amp;= 2 \left(
  \mathbf{x}'\mathbf{x}\bm{\beta} - \mathbf{x}' \mathbf{y}
\right)
\end{align}
\]</span></p>
</div>
</div>
</div>
<p>Now, remember that <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are sample data. We can <em>estimate</em> the coefficient vector by setting the gradient to zero and solving for it</p>
<p><span class="math display">\[
\begin{align}
2 \left(
  \mathbf{x}'\mathbf{x}\hat{\bm{\beta}} - \mathbf{x}' \mathbf{y}
  \right)
  &amp;= 0 \\
\mathbf{x}'\mathbf{x}\hat{\bm{\beta}} - \mathbf{x}' \mathbf{y} &amp;= 0 \\
\mathbf{x}'\mathbf{x}\hat{\bm{\beta}} &amp;= \mathbf{x}' \mathbf{y} \\
\hat{\bm{\beta}} &amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \mathbf{y}.
\end{align}
\]</span></p>
<p>To confirm that <span class="math inline">\(\hat{\bm{\beta}}\)</span> represents a <em>minimum</em>, we can do a second derivative test. This involves computing the Hessian by differentiating the gradient with respect to <span class="math inline">\(\bm{\beta}\)</span> again, yielding <span class="math inline">\(2 \mathbf{x}'\mathbf{x}\)</span>. If <span class="math inline">\(\mathbf{x}\)</span> is full rank and positive semi-definite then so is its Gram matrix <span class="math inline">\(\mathbf{x}'\mathbf{x}\)</span>, and the vector <span class="math inline">\(\hat{\bm\beta}\)</span> is a minimum.</p>
<section id="elements-of-hatboldsymbolbeta" class="level2">
<h2 class="anchored" data-anchor-id="elements-of-hatboldsymbolbeta">Elements of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></h2>
<p>Okay so we’ve seen that the estimating equation <span class="math inline">\(\left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \mathbf{y}\)</span> results in a vector of parameter estimates that minimizes the RSS, but let’s make sure that the elements in <span class="math inline">\(\hat{\bm{\beta}}\)</span> indeed correspond to their scalar counterparts.</p>
<p>Specifically, let’s verify that</p>
<p><span class="math display">\[
\hat{\bm{\beta}} =
\begin{bmatrix}\hat\beta_0 \\ \hat\beta_1\end{bmatrix} =
\begin{bmatrix}
\bar y -  \hat \beta_1 \bar x \\
\frac{{\text{Cov}(x, y)}}{\hat \sigma^2_x}
\end{bmatrix}.
\]</span></p>
<p>As a starting point, we’ll introduce a normalizing factor <span class="math inline">\(n^{-1}\)</span> to the estimating equation<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> so that</p>
<p><span class="math display">\[
\hat{\bm{\beta}} =
\left(
   n^{-1}\mathbf{x}'\mathbf{x}
\right)^{-1} n^{-1}\mathbf{x}'\mathbf{y}.
\]</span></p>
<hr>
<p>We’ll compute this product in parts, beginning with the terms inside the parentheses. I’ll note here that in what follows, estimates of variances are defined as their maximum likelihood estimates.</p>
<p><span class="math display">\[
\begin{align}
n^{-1}\mathbf{x}'\mathbf{x} &amp;=
\frac1n
\begin{bmatrix}
1 &amp; \dots &amp; 1 \\
x_1 &amp; \dots &amp; x_n
\end{bmatrix}
\begin{bmatrix}
1 &amp; x_1 \\
\vdots &amp; \vdots \\
1 &amp; x_n
\end{bmatrix} \\
% ---------
&amp;= \frac1n \begin{bmatrix}
n &amp; \sum x_i \\
\sum x_i &amp; \sum x^2_i
\end{bmatrix} \\
% ---------
&amp;= \begin{bmatrix}
1 &amp; \bar{x}\\
\bar{x}&amp; \bar{x^2}
\end{bmatrix}
\end{align}
\]</span></p>
<p>Let’s not forget that we need to find the inverse of the resulting matrix <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p><span class="math display">\[
\begin{align}
\left(n^{-1}\mathbf{x}'\mathbf{x}\right)^{-1} &amp;=
  \begin{bmatrix}
    1 &amp; \sum \bar{x}\\
    \bar{x}&amp; \sum \bar{x^2}
  \end{bmatrix}^{-1} \\
% ---------
&amp;= \frac{1}{\bar{x^2} - \bar{x}^2} \begin{bmatrix}
\bar{x^2} &amp; -\bar{x}\\
-\bar{x} &amp; 1  
\end{bmatrix}\\
% ---------
&amp;= \frac{1}{\hat\sigma^2_x} \begin{bmatrix}
\bar{x^2} &amp; -\bar{x}\\
-\bar{x} &amp; 1  
\end{bmatrix}.
\end{align}
\]</span></p>
<ul>
<li>We get <span class="math inline">\(\hat\sigma^2_x\)</span> because <span class="math inline">\(\bar{x^2} - \bar{x}^2\)</span> estimates <span class="math inline">\(\mathbb{V}[x] = \mathbb{E}[x^2] - \mathbb{E}[x]^2\)</span>.</li>
</ul>
<hr>
<p>Next, we’ll work through the term outside the parentheses</p>
<p><span class="math display">\[
\begin{align}
n^{-1}\mathbf{x}'\mathbf{y} &amp;=
\frac1n \begin{bmatrix}
  1 &amp; \dots &amp; 1 \\
  x_1 &amp; \dots &amp; x_n
\end{bmatrix}
\begin{bmatrix}
  y_i \\
  \vdots \\
  y_n
\end{bmatrix}\\
% ---------
&amp;= \frac1n \begin{bmatrix}
  \sum y_i \\
  \sum x_i y_i
\end{bmatrix} \\
% ---------
&amp;= \begin{bmatrix}
\bar{y} \\
\overline{xy}
\end{bmatrix}.
\end{align}
\]</span></p>
<hr>
<p>Stitching it all together results in the following vector</p>
<p><span class="math display">\[
\begin{align}
\hat{\bm{\beta}} &amp;=
\left(
  n^{-1}\mathbf{x}'\mathbf{x}
\right)^{-1} n^{-1}\mathbf{x}'\mathbf{y} \\
% ---------
&amp;= \frac{1}{\hat\sigma^2_x}
\begin{bmatrix}
  \bar{x^2} &amp; -\bar{x}\\
  -\bar{x} &amp; 1  
\end{bmatrix}
\begin{bmatrix}
  \bar{y} \\
  \overline{xy}
\end{bmatrix} \\
% ---------
&amp;= \frac{1}{\hat\sigma^2_x}
\begin{bmatrix}
  \bar{x^2}\bar{y} - \bar{x} \overline{xy} \\
  - \bar{x} \bar{y} + \overline{xy}
\end{bmatrix}.
% ---------
\end{align}
\]</span></p>
<p>We’ve made good progress up to this point, but it still feels unclear how the elements of this vector correspond to the scalar equations for <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>. To continue, we’ll have re-express the elements of the vector by taking advantage of the following definitions</p>
<ul>
<li><span class="math inline">\(\hat{\sigma^2_x} = \bar{x^2} - \bar{x}^2\)</span></li>
<li><span class="math inline">\(\hat{\text{Cov}(x, y)} = \overline{xy} - \bar{x}\bar{y}\)</span>.</li>
</ul>
<p>Doing so lets us re-express the vector as follows <span class="math display">\[
\begin{align}
&amp;= \frac{1}{\hat\sigma^2_x}
\begin{bmatrix}
  \left(\hat\sigma^2_x + \bar{x}^2\right)\bar{y} - \bar{x}\left(\hat{\text{Cov}(x,y)} + \bar{x} \bar{y}\right) \\
  \hat{\text{Cov}(x,y)}
\end{bmatrix} \\
% ---------
&amp;= \frac{1}{\hat\sigma^2_x}
\begin{bmatrix}
  \hat\sigma^2_x\bar{y} + \bar{x}^2\bar{y} - \bar{x}\hat{\text{Cov}(x,y)} - \bar{x}^2 \bar{y} \\
  \hat{\text{Cov}(x,y)}
\end{bmatrix}.
% ---------
\end{align}
\]</span></p>
<p>Out last task here is distributing <span class="math inline">\(\frac{1}{\hat\sigma^2_x}\)</span> and simplifying</p>
<p><span class="math display">\[
\begin{align}
&amp;=
\begin{bmatrix}
  \bar{y} - \frac{\hat{\text{Cov}(x,y)}}{\hat\sigma^2_x}\bar{x} \\
  \frac{\hat{\text{Cov}(x,y)}}{\hat\sigma^2_x}
\end{bmatrix} \\
% ---------
&amp;=
\begin{bmatrix}
  \bar{y} - \hat\beta_1\bar{x} \\
  \hat \beta_1
\end{bmatrix}.
\end{align}
\]</span></p>
<p>And there it is. Although it was a bit tedious, we can see that the elements in <span class="math inline">\(\hat{\bm{\beta}}\)</span> indeed correspond to the scalar equations for <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>.</p>
</section>
</section>
<section id="deriving-the-sampling-distribution-of-hatboldsymbolbeta" class="level1">
<h1>Deriving the sampling distribution of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></h1>
<p>To perform hypothesis tests and compute confidence intervals for the elements in <span class="math inline">\(\hat{\bm{\beta}}\)</span>, we need to understand its sampling distribution. We can do this by splitting <span class="math inline">\(\hat{\bm{\beta}}\)</span> into a deterministic part and a random part.</p>
<p>Note that up to this point, we haven’t made any distributional assumptions. Now, though, we’ll make the usual assumption that the residuals are distributed <span class="math inline">\(\bm{\epsilon} \sim \mathcal{N}\left(\mathbf{0}, \sigma^2_{\epsilon}\mathbf{I}\right)\)</span>.</p>
<p>Remember that we’ve defined <span class="math inline">\(\mathbf{y} = \mathbf{x}\bm{\beta} + \bm{\epsilon}\)</span> so</p>
<p><span class="math display">\[
\begin{align}
  \hat{\bm{\beta}} &amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \mathbf{y} \\
  % ---------
  &amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \left(\mathbf{x}\bm{\beta} + \bm{\epsilon}\right) \\
  % ---------
  &amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\mathbf{x}\bm{\beta} +  \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon} \\
  % ---------
  &amp;= \bm{\beta} + \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}.
\end{align}
\]</span></p>
<p>Taking the expectation we get</p>
<p><span class="math display">\[
\begin{align}
\mathbb{E}[\hat{\bm{\beta}}] &amp;= \mathbb{E}[\bm{\beta} + \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}] \\
% ---------
&amp;= \mathbb{E}[\bm{\beta}] + \mathbb{E}[\left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}] \\
% ---------
&amp;= \bm{\beta} + \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\mathbb{E}[\bm{\epsilon}] \\
% ---------
&amp;=  \bm{\beta}.
\end{align}
\]</span></p>
<p>Now, turning our attention to the variance-covariance matrix of the coefficients</p>
<p><span class="math display">\[
\begin{align}
\mathbb{V}[\hat{\bm{\beta}}] &amp;= \mathbb{V}[\bm{\beta} + \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}] \\
% ---------
&amp;= \mathbb{V}[\bm{\beta}] + \mathbb{V}[\left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}]
\end{align}
\]</span></p>
<p>The variance of <span class="math inline">\(\bm{\beta}\)</span> is 0 because it is a fixed vector. To compute the variance for the remaining term we’ll use the fact that if <span class="math inline">\(\mathbf{a}\)</span> is fixed and <span class="math inline">\(\mathbf{X}\)</span> is random, then <span class="math inline">\(\mathbb{V}[\mathbf{a}\mathbf{X}] = \mathbf{a} \mathbb{V}[\mathbf{X}]\mathbf{a}'\)</span></p>
<p><span class="math display">\[
\begin{align}
&amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \mathbb{V}[\bm{\epsilon}] \left( \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\right)' \\
% ---------
&amp;= \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}' \sigma^2_{\epsilon}\mathbf{I} \mathbf{x}\left(\mathbf{x}'\mathbf{x}\right)^{-1} \\
% --------- Multiplying by I does't change the matrix
&amp;= \sigma^2_{\epsilon}  \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\mathbf{x}\left(\mathbf{x}'\mathbf{x}\right)^{-1} \\
% ---------
&amp;= \sigma^2_{\epsilon}  \left(\mathbf{x}'\mathbf{x}\right)^{-1}.
\end{align}
\]</span></p>
<p>Great, our work has shown that the estimated regression coefficients are normally distributed<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> with mean vector <span class="math inline">\(\bm\beta\)</span>, and variance-covariance matrix <span class="math inline">\(\bm{\Sigma} = \sigma^2_{\epsilon}  \left(\mathbf{x}'\mathbf{x}\right)^{-1}\)</span></p>
<p><span class="math display">\[
\hat{\bm\beta} \sim \mathcal{N} \left(\bm{\beta}, \bm{\Sigma}\right).
\]</span></p>
<p>In practice, we don’t know <span class="math inline">\(\sigma^2_{\epsilon}\)</span> so we estimate <span class="math inline">\(\hat{\bm{\Sigma}} = \hat{\sigma^2_\epsilon}\left(\mathbf{x}'\mathbf{x}\right)^{-1}\)</span> for inferences.</p>
<section id="elements-of-the-variance-covariance-matrix" class="level2">
<h2 class="anchored" data-anchor-id="elements-of-the-variance-covariance-matrix">Elements of the variance-covariance matrix</h2>
<p>As we did with the parameter estimates, we want to make sure that the matrix representation of parameter variances correspond to their scalar counterparts.</p>
<p>To verify, we’ll again start by adding in a normalizing term of <span class="math inline">\(n^{-1}\)</span> so that</p>
<p><span class="math display">\[
\begin{align}
{\bm{\Sigma}} &amp;= n^{-1}\sigma^2_{\epsilon}  \left(n^{-1}\mathbf{x}'\mathbf{x}\right)^{-1} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}}{n}  \left(\frac{1}{\hat\sigma^2_x} \begin{bmatrix}
\bar{x^2} &amp; -\bar{x}\\
-\bar{x} &amp; 1  
\end{bmatrix}
\right).
\end{align}
\]</span></p>
<p>The variance for <span class="math inline">\(\hat\beta_0\)</span> corresponds to the first diagonal element of <span class="math inline">\({\bm{\Sigma}}\)</span>. Multiplying the relevant terms gets us</p>
<p><span class="math display">\[
\begin{align}
\mathbb{V}[\hat\beta_0] &amp;= \frac{\sigma^2_{\epsilon}}{n} \cdot \frac{1}{\hat\sigma^2_x} \cdot \bar{x^2} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}\bar{x^2} }{n \hat\sigma^2_x} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}( \bar{x}^2  + \hat\sigma^2_x )}{n \hat\sigma^2_x} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}\bar{x}^2  + \sigma^2_{\epsilon}\hat\sigma^2_x}{n \hat\sigma^2_x} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}\bar{x}^2}{n \hat\sigma^2_x} + \frac{\sigma^2_{\epsilon}\hat\sigma^2_x}{n \hat\sigma^2_x} \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}}{n} \left(
  \frac{\bar{x}^2}{\sigma^2_x} + 1
\right).
\end{align}
\]</span></p>
<p>The variance for <span class="math inline">\(\hat\beta_1\)</span> corresponds to the second diagonal element of <span class="math inline">\({\bm{\Sigma}}\)</span>, and again multiplying the relevant terms</p>
<p><span class="math display">\[
\begin{align}
\mathbb{V}[\hat\beta_1] &amp;= \frac{\sigma^2_{\epsilon}}{n} \cdot \frac{1}{\hat\sigma^2_x} \cdot 1 \\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}}{n} \cdot \frac{1}{\frac{\sum (x_i - \bar{x})^2}{n}}\\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}}{\frac{n\sum (x_i - \bar{x})^2}{n}}\\
% ---------
&amp;= \frac{\sigma^2_{\epsilon}}{\sum_{i=1}^n\left(x_i - \bar{x}\right)^2}.
\end{align}
\]</span></p>
<p>With that, we’ve shown that the matrix representation of the parameter variances also match their scalar representations.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Well. There you have it. By working through the derivations, we’ve demonstrated that the OLS regression parameter estimates and their variances derived in matrix form are equivalent to those obtained from the traditional scalar notation.</p>
<p>We don’t need to remember every step, but we can feel confident that the scalar and matrix notations of OLS regression lead to the same results now that we’ve “seen it once”.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>This will be handy in letting us define the elements in the relevant vectors and matrices as means and variances.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The inverse of a <span class="math inline">\(2 \times 2\)</span> matrix is given by <span class="math inline">\(\left[\begin{smallmatrix}a &amp; b \\ c &amp; d\end{smallmatrix}\right]^{-1} = \frac{1}{ad-bc}\left[\begin{smallmatrix}d &amp; -b \\ -c &amp; a\end{smallmatrix}\right]\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This stems from the fact that we defined <span class="math inline">\(\hat{\bm{\beta}} = \bm{\beta} + \left(\mathbf{x}'\mathbf{x}\right)^{-1}\mathbf{x}'\bm{\epsilon}\)</span> and the normality of <span class="math inline">\(\bm{\epsilon}\)</span> is preserved under affine transformations.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>