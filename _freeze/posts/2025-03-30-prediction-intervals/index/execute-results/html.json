{
  "hash": "4b745c81c55b46f630e0e5a78eea380e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Prediction Intervals\ndescription: |\n What is a prediction interval? How would you use one?\ndate: \"2025-03-31\"\nformat:\n  html\ntoc-depth: 1\ncode-fold: true\n---\n\n\n\n\n\n# What is a prediction interval?\n\nA $100(1-\\alpha)\\%$ prediction interval is an interval for a *future* observation of a random variable $Y$, conditioned on the observed data $X$, and can be defined as\n\n$$\nP(l \\leq Y = y_0 \\leq u | X = x_0) = 1 - \\alpha.\n$$\n\nIn other words, a prediction interval is an interval that allows you to make statements like\n\n> If we were to observe a new value $X = x_0$, then there's a $95\\%$ chance that the corresponding $Y$ value, $y_0$, will be between $l$ and $u$.\n\nThis seems like a pretty useful concept to me? It's a powerful thing to quantify the uncertainty around a future observation. For example, you might want to predict the likely range of effects of medicine on a specific individual given a set of patient characteristics, or you might want to forecast likely levels of user engagement for a new user of your product.\n\nNote that a prediction interval is *not* the same thing as a confidence interval. I won't go over the difference here, but you can read about confidence intervals in my [previous blog post](https://josue-rodriguez.github.io/posts/2024-11-27-confidence-interval-alt-definition/), or elsewhere on the internet. You can also check out [this excellent post](https://robjhyndman.com/hyndsight/intervals/) by Rob Hyndman where he discusses the differences. \n\n## Predicting canine separation anxiety\n\nIn this post, we'll pretend we're looking to adopt a dog. One thing that's important to anticipate is how much separation anxiety a newly adopted dog might experience. Prediction intervals can help us accomplish this.\n\nLet's say that we know that a particular measure of canine excitability ($X$) is related to a canine measure of anxiety separation ($Y$) through the following relationship\n\n$$\nY | X = x_i \\sim \\mathcal{N}\\left(\\beta_1 x_i , \\; \\sigma^2\\right),\n$$\n\n\nwhere $\\beta_1 = 1.5$, and $\\sigma^2 = 1.2$. Let's simulate data from this scenario and visualize it.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(glue)\n\nset.seed(1)\n\ntheme_set(theme_minimal())\n\nb1 <- 1.5\nsigma2 <- 1.2\n\nn <- 100\nx <- rnorm(n)\ny <- rnorm(n, mean = b1 * x, sd = sqrt(sigma2))\n\ncanine_behavior_df <- data.frame(excitability = x, sepanx = y)\n\nggplot(canine_behavior_df, aes(x, y)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = b1, col = \"steelblue\", lwd = 1) +\n  geom_vline(xintercept = 0.5, lty = \"dashed\", col = \"gray50\") +\n  geom_hline(yintercept = b1 * 0.5, lty = \"dashed\", col = \"gray50\") +\n  labs(x = \"Excitability\", y = \"Separation Anxiety\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nLet's also say that we know that the dogs at our local shelter often have excitability scores of $x_0 = 0.5$. What would be our best guess for a dog's separation anxiety score if they indeed had this excitability score? How could we come up with a range of plausible separation anxiety scores for such dogs?\n\nIn this fictitious scenario, we know the true parameter values, and we therefore know that the distribution of separation anxiety scores for dogs with excitability scores of $0.5$ is $\\mathcal{N}\\left(0.75 = 1.5(0.5), 1.2\\right)$. \n\nOur best guess for our potential future dog's separation anxiety would therefore be $\\hat{y} = 0.75$ -- the mean of conditional separation anxiety distribution, and where the dashed lines intersect the blue line in the plot above. \n\nHowever, there's variability in separation anxiety for dogs with excitability scores of $0.5$; this variability is captured by $\\sigma^2$. To get a sense of the range of separation anxiety levels observable in a dog with an excitability score of $0.5$, we could compute a $95\\%$ prediction interval by taking the $0.025$ and $0.975$ quantiles of the conditional separation anxiety distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(c(lwr = 0.025, upr = 0.975), mean = b1 * 0.5, sd = sqrt(sigma2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      lwr       upr \n-1.397033  2.897033 \n```\n\n\n:::\n:::\n\n\n\nThis interval tells us that if we were to observe a dog with an excitability score of $0.5$, there's a $95\\%$ chance its separation anxiety score is between $-1.4$ and $2.9$.\n\nGenerally, we could compute a $100(1-\\alpha)\\%$ prediction interval as\n\n$$\n\\left[ \\hat{y} - z_\\text{crit} \\sigma,\\; \\hat{y} + z_\\text{crit} \\sigma\\right],\n$$\n\nwhere $z_\\text{crit}$ corresponds to the $1 - \\alpha/2$ quantile of a standard Normal distribution.\n\nWe can visualize the $95\\%$ prediction interval along the entire range of excitability scores to get a sense of what separation anxiety scores might look like for dogs with different excitability scores. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nxrange <- seq(min(x), max(x), length.out = n)\nlwr_bounds <- sapply(xrange, \\(x) qnorm(0.025, mean = b1 * x, sd = sqrt(sigma2)))\nupr_bounds <- sapply(xrange, \\(x) qnorm(0.975, mean = b1 * x, sd = sqrt(sigma2)))\nbounds <- data.frame(x = xrange, lwr = lwr_bounds, upr = upr_bounds)\n\nggplot(canine_behavior_df, aes(x, y)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = b1, col = \"steelblue\", lwd = 1) +\n  geom_ribbon(data = bounds, aes(ymin = lwr, ymax = upr), alpha = 0.2, fill = \"orange\") + \n  labs(x = \"Excitability\", y = \"Separation Anxiety\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nSo, if we knew the true parameter values, and we observed a dog to have an excitability score of $0.5$, then we would expect the dog to have a separation anxiety score of about $0.75$, but we shouldn't be surprised to see its score be anywhere from $-1.4$ to $2.9$. That's substantially more or less than our best guess.\n\n___\n\nA very important caveat is that we've assumed that we know the true parameter values. We never actually do know these values though! We estimate them. \n\nLet's now simulate a scenario in which we don't know the true parameter values and instead estimate them by fitting a regression model to historical data. Here we will use the data we previously generated as our \"historical data\".\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexc_sepanx_fit <- lm(sepanx ~ excitability, data = canine_behavior_df)\nsummary(exc_sepanx_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sepanx ~ excitability, data = canine_behavior_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0560 -0.6724 -0.1528  0.5909  2.5701 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.04129    0.10624  -0.389    0.698    \nexcitability  1.49884    0.11801  12.701   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.055 on 98 degrees of freedom\nMultiple R-squared:  0.6221,\tAdjusted R-squared:  0.6182 \nF-statistic: 161.3 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nNow our best guess for the conditional mean is $\\hat{y} = -0.04 + 1.5(0.5) = 0.71$ and our estimate of the residual variance is $\\hat{\\sigma^2} = 1.11$. \n\nIt might seem sensible here to generate a prediction interval by taking the quantiles of a $\\mathcal{N}\\left(0.71, 1.11\\right)$ distibution, but this ignores newly introduced sources of variability! There is variability (i.e., uncertainty) in our estimates $\\hat{y}$ and $\\hat{\\sigma^2}$.\n\nThis uncertainty is accounted for by the *standard error of the prediction*:\n$$\n\\text{SE}(\\hat y) = \\sqrt{\\hat{\\sigma^2}\\left(1 + \\frac1n + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)}.\n$$\n\nWe can use the standard error to compute a $100(1-\\alpha)\\%$ prediction interval as\n$$\n\\left[\\hat{y}-t_\\text{crit}\\text{SE}(\\hat y), \\; \\hat{y} + t_\\text{crit} \\text{SE}(\\hat y)\\right],\n$$\n\nwhere $t_\\text{crit}$ corresponds to the $1 - \\alpha/2$ quantile of a $\\text{Student-}t$ distibution with $n-2$ degrees of freedom. \n\nThe `predict` function in R lets us conveniently compute such a prediction interval from our fitted regression.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nx0_df <- data.frame(excitability = 0.5)\n\npredict(exc_sepanx_fit, newdata = x0_df, interval = \"prediction\", level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       fit       lwr      upr\n1 0.708129 -1.397208 2.813466\n```\n\n\n:::\n:::\n\n\n\nWe can see that this $95\\%$ prediction interval is very similar to the one we computed using the \"true\" distribution. This should gives us some confidence in using prediction intervals. \n\nJust to be sure that our new interval lines up with the formula we saw for the standard error of prediction, let's compute the interval manually and check it against the output from the `predict` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nx0 <- 0.5\nalpha <- 0.05\n\nbeta_hats <- as.vector(coef(exc_sepanx_fit))\nyhat <- beta_hats[1] + beta_hats[2] * x0\n\nsigma_hat <- sigma(exc_sepanx_fit)\n\nvar_pred <- sigma_hat^2 * (1 + (1/n) + ((x0 - mean(x))^2 / sum((x - mean(x))^2) ))\nse_pred <- sqrt(var_pred)\n\nt_crit <- qt(1 - (alpha/2), df = n - 2)\n\nc(\n  fit = yhat,\n  lwr = yhat - t_crit * se_pred,\n  upr = yhat + t_crit * se_pred\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      fit       lwr       upr \n 0.708129 -1.397208  2.813466 \n```\n\n\n:::\n:::\n\n\n\nExcellent, we can rest easy knowing that the prediction interval we get from R is the one we would get if we computed it \"by hand\".\n\nNext, let's briefly inspect what would have happened if we had simply taken the quantiles of a Normal distribution with the estimated mean, $\\hat{y} = 0.71$ and residual variance, $\\hat{\\sigma^2} = 1.11$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(c(0.025, 0.975), mean = yhat, sd = sigma_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.358934  2.775192\n```\n\n\n:::\n:::\n\n\n\nThe bounds of this interval are very similar to the two preceding ones, but it's slightly narrower. In fact, we should expect this interval to always be narrower than one that accounts for estimation uncertainty. However, not properly accounting for uncertainty will lead to overconfidence in the range of expected outcomes. \n\n\nLastly, let's visualize both prediction intervals to see how they compare along the entire range of $X$ values.\n\n\n\n::: {.cell .preview-image layout-align=\"center\"}\n\n```{.r .cell-code}\npred_lwr_bounds <- sapply(xrange, \\(x) qnorm(0.025, mean = beta_hats[1] + beta_hats[2] * x, sd = sigma_hat))\npred_upr_bounds <- sapply(xrange, \\(x) qnorm(0.975, mean = beta_hats[1] + beta_hats[2] * x, sd = sigma_hat))\npred_bounds <- data.frame(x = xrange, lwr = pred_lwr_bounds, upr = pred_upr_bounds)\n\npreds <- predict(exc_sepanx_fit, newdata = canine_behavior_df, interval = \"prediction\")\n\nggplot(canine_behavior_df, aes(x, y)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = b1, col = \"steelblue\", lwd = 1) +\n  geom_ribbon(data = pred_bounds, aes(y = lwr, ymin = lwr, ymax = upr), alpha = 0.2, col = \"gray50\",  fill = \"plum\", lty = \"dashed\") + \n  geom_ribbon(data = preds, aes(ymin = lwr, ymax = upr), alpha = 0.2, col = \"gray50\", fill = \"orange\") + \n  labs(x = \"Excitability\", y = \"Separation Anxiety\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nJust as we saw for $x_0 = 0.5$, the correct prediction interval is slightly wider across the entire range of excitability scores. Interestingly, in this example, the prediction interval lets us see that even dogs with low excitability scores would have a chance of having a separation anxiety score greater than 0 and vice-versa.\n\n\n\n## What should we be prepared for?\n\nIn conclusion, computing a prediction interval for canine separation anxiety based on canine excitability has helped us understand one aspect of preparation for adopting a new furry friend.\n\nThe dog we want to adopt has an excitability score of $0.5$, and although we should expect a dog with *some* separation anxiety, we should prepare for anything from very low or no separation anxiety to very high levels of separation anxiety! Time to start reading up on how to help our future pet feel comfortable and relaxed when left alone in their new home. \n\n\n# Deriving a prediction interval\n\nTo understand how a prediction interval is derived, it will be helpful to consider the following hypothesis test:\n\n$$\n\\begin{aligned}\nH_0{:\\;}  \\hat{y}& -  y_0 = 0 \\\\\n& \\text{ vs. } \\\\\nH_1{:\\;} \\hat{y}& -  y_0 \\neq 0\n\\end{aligned}\n$$ \n  \n\nThat is, we have predicted value of $Y|X=x_0$ that we've labeled $\\hat{y}$, and a value that we have not yet observed labeled $y_0$.  We want to test whether the difference between $\\hat{y}$ and  $y_0$ is zero.\n\nTo construct a test statistic, we need a standard error for the difference between $\\hat{y}$ and $y_0$. To obtain this standard error, we need\n\n1. The variance of the predicted value, $\\hat{y}$. \n   $$\\text{Var}\\left[\\hat{y}\\right] = \\sigma^2 \\left(\\frac1n + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)$$\n\n2. The variance of the to-be-observed $Y$ value, $y_0$. This is just the variance of $Y$.\n   $$\\text{Var}\\left[y_0\\right] = \\sigma^2$$\n\n\nBecause $\\hat{y}$ and $y_0$ are independent (our prediction for a future observation is independent of the future observation itself), the variance of their difference is just the sum of their variances\n\n$$\n\\begin{aligned}\n\\text{Var}\\left[\\hat{y} - y_0 \\right] &=  \\text{Var}\\left[\\hat{y}\\right] + \\text{Var}\\left[y_0\\right]\\\\\n&= \\sigma^2 \\left(\\frac1n + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right) + \\sigma^2\\\\\n&= \\sigma^2 \\left(1 + \\frac1n + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right).\n\\end{aligned}\n$$\n\nThe standard error of the difference is then\n$$\n\\text{SE}(\\hat{y} -  y_0) = \\sqrt{\\sigma^2 \\left(1 + \\frac1n + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)},\n$$\n\nwhich is the same as the standard error prediction we saw earlier in this post!\n\nNext, we can construct a $t$-statistic as\n$$\n\\frac{\\hat{y} -  y_0}{\\text{SE}(\\hat{y} -  y_0)}.\n$$\n\nWe fail to reject $H_0$ whenever\n\n$$\n\\left|\\frac{\\hat{y} -  y_0}{\\text{SE}(\\hat{y} -  y_0)}\\right| < t_\\text{crit},\n$$\nwhere $t_\\text{crit}$ again corresponds to the $1 - \\alpha/2$ quantile of a $\\text{Student-}t$ distribution with $n-2$ degrees of freedom.\n\nThis expression allows us to invert the hypothesis test to obtain the prediction interval\n\n$$\n\\begin{aligned}\n-t_\\text{crit} <& \\frac{\\hat{y} -  y_0}{\\text{SE}(\\hat{y} -  y_0)} < t_\\text{crit} \\\\\n-t_\\text{crit}\\text{SE}(\\hat{y} -  y_0) <& \\; \\hat{y} -  y_0 < t_\\text{crit}\\text{SE}(\\hat{y} -  y_0) \\\\\n\\hat{y} - t_\\text{crit}\\text{SE}(\\hat{y} -  y_0) <& \\; y_0 < \\hat{y} + t_\\text{crit}\\text{SE}(\\hat{y} -  y_0).\n\\end{aligned}\n$$",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}